{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df8f8c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# sekcja serwisowa\n",
    "import spacy\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "import pandas as pd\n",
    "df = pd.DataFrame\n",
    "pd.set_option('display.max_rows', None) # nie skracaj tabeli df\n",
    "pd.set_option('max_colwidth', 500) # maksymalna dopuszczalna szerokość kolumny df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PODAJ STOPWORD\n",
    "stopword = \"stop\"\n",
    "# PODAJ TYTUŁ\n",
    "title = \"System zarządzania sklepem\"\n",
    "# PODAJ ŚCIEŻKĘ DO PLIKU TEKSTOWEGO - ZAPISU ROZMOWY\n",
    "source = \"klient1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zwrotka dla użytkownika\n",
    "f = open(source, \"r\", encoding=\"utf-8\")\n",
    "tekst = f.read()\n",
    "\n",
    "if stopword in tekst:\n",
    "    print(\"Wybierz inny stopword!\")\n",
    "else:\n",
    "    doc = nlp(tekst)\n",
    "    print(\"OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74012f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wyświetla token oraz przypisaną do niego część mowy, dep i head\n",
    "colttext, coltpos, coltdep, colhdtx = \"\", \"\", \"\", \"\"\n",
    "tokcol1, tokcol2, tokcol3, tokcol4 = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for token in doc:\n",
    "    tokcol1 += token.text + stopword\n",
    "    tokcol2 += token.pos_ + stopword\n",
    "    tokcol3 += token.dep_ + stopword\n",
    "    tokcol4 += token.head.text + stopword\n",
    "colttext = tokcol1.split(stopword)\n",
    "coltpos = tokcol2.split(stopword)\n",
    "coltdep = tokcol3.split(stopword)\n",
    "colhdtx = tokcol4.split(stopword)\n",
    "tok = {'token' : colttext, 'część mowy' : coltpos, 'dep' : coltdep, 'head' : colhdtx}\n",
    "\n",
    "df(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d237e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zasady służące do wyłapywania w tekście akcji i aktorów - serce skryptu\n",
    "podmioty, orzeczenia, zdania = [], [], []\n",
    "\n",
    "for token in doc:\n",
    "    # wyłapuje podmioty które są rzeczownikiem lub nazwą własną\n",
    "    if token.dep_ == \"nsubj\" and (token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\"):\n",
    "        podmioty.append(token.text.lower())\n",
    "        orzeczenia.append(token.head.text.lower())\n",
    "        zdania.append(token.sent)\n",
    "        \n",
    "    # wyłapuje czasowniki\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        orzeczenia.append(token.text.lower())\n",
    "        podmioty.append(\"null\")\n",
    "        zdania.append(token.sent)\n",
    "    \n",
    "    # wyłapuje czasowniki posiłkowe CHYBA\n",
    "    elif token.pos_ == \"AUX\":\n",
    "        orzeczenia.append(token.text.lower() + \" \" + token.head.text.lower())\n",
    "        podmioty.append(\"null\")\n",
    "        zdania.append(token.sent)\n",
    "        \n",
    "    # wyłapuje czasowniki posiłkowe\n",
    "    elif token.pos_ == \"PRON\" and token.dep_ == \"expl:pv\":\n",
    "        orzeczenia.append(token.head.text.lower() + \" \" + token.text.lower())\n",
    "        podmioty.append(\"null\")\n",
    "        zdania.append(token.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eksportuje do .xlsx wynik\n",
    "oip = {}\n",
    "oip = {\"Aktorzy\" : podmioty, \"Akcje\" : orzeczenia, \"Zdanie\" : zdania}\n",
    "df(oip).to_excel(\"./data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855dabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutaj konieczna jest interwencja użytkownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352cd73d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# importuje z .xlsx, usuwa zduplikowane wiersze\n",
    "excel = pd.read_excel(\"./data.xlsx\")\n",
    "df2 = df.drop_duplicates(excel)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwa kopie gdzie brakuje czasowników posiłkowych\n",
    "aktorzy = list(df2['Aktorzy'])\n",
    "akcje = list(df2['Akcje'])\n",
    "aktorzy.append(stopword)\n",
    "aktorzy.append(stopword)\n",
    "akcje.append(stopword)\n",
    "akcje.append(stopword)\n",
    "\n",
    "i=0\n",
    "for i in range (0,len(df2['Akcje'])):\n",
    "    if aktorzy[i] == aktorzy[i+1]:\n",
    "        if akcje[i] == (akcje[i+1] + \" się\"):\n",
    "            aktorzy.remove(aktorzy[i+1])\n",
    "            akcje.remove(aktorzy[i+1])\n",
    "        elif (akcje[i] + \" się\") == akcje[i+1]:\n",
    "            aktorzy.remove(aktorzy[i])\n",
    "            akcje.remove(akcje[i])\n",
    "        i += 1\n",
    "        \n",
    "for i in range(0,len(aktorzy)):\n",
    "    if stopword in aktorzy:\n",
    "        aktorzy.remove(stopword)\n",
    "    elif stopword in akcje:\n",
    "        akcje.remove(stopword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabela aktorów, przypisanych do nich akcji i zdań w których występują\n",
    "final = {}\n",
    "final = {\"Aktorzy\" : aktorzy, \"Akcje\" : akcje, \"Zdanie\" : zdania}\n",
    "df(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1eb08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generuje wykres z aktorami i przypisanymi akcjami\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "dlugosc = len(aktorzy)\n",
    "if dlugosc > 8:\n",
    "    dlugosc = 8\n",
    "i=0\n",
    "\n",
    "ax.text(0.25, 0.95, title, color = 'black')\n",
    "\n",
    "for i in range(0, dlugosc):\n",
    "    aktor = aktorzy[i]\n",
    "    akcja = akcje[i]\n",
    "    ax.text(0.3, 0.8 - 0.1*i, aktor + ' ---> ' + akcja, color='black')\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0bb16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b57153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyjaśnia skróty\n",
    "spacy.explain(\"PRON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1accfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generuje wykres\n",
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", jupyter=True) # ent/dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d56b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff249dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nazwy własne np miejsca, organizacje\n",
    "colenttext, colentlabel, entcol1, entcol2 = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for ent in doc.ents:\n",
    "    entcol1 += ent.text + stopword\n",
    "    entcol2 += ent.label_ + stopword\n",
    "colenttext = entcol1.split(stopword)\n",
    "colentlabel = entcol2.split(stopword)\n",
    "ent = {'tekst' : colenttext, 'etykieta' : colentlabel}\n",
    "\n",
    "df(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa21ead7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# morfologia\n",
    "colmortext, colmormor, morcol1, morcol2 = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for token in doc:\n",
    "    morcol1 += token.text + stopword\n",
    "    morcol2 += str(token.morph) + stopword\n",
    "colmortext = morcol1.split(stopword)\n",
    "colmormor = morcol2.split(stopword)\n",
    "morph = {'tekst' : colmortext, 'morfologia' : colmormor}\n",
    "\n",
    "df(morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad288c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lemmatizacja\n",
    "collemtext, collemlem, lemcol1, lemcol2 = \"\", \"\", \"\", \"\"\n",
    "\n",
    "for token in doc:\n",
    "    lemcol1 += token.text + stopword\n",
    "    lemcol2 += str(token.lemma_) + stopword\n",
    "collemtext = lemcol1.split(stopword)\n",
    "collemlem = lemcol2.split(stopword)\n",
    "lemma = {'tekst' : collemtext, 'lemmatyzacja' : collemlem}\n",
    "\n",
    "df(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230d542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for chunk in doc.noun_chunks:\n",
    "#     print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "#             chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3279d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for token in doc:\n",
    "#     print(token.text, token.dep_, token.head.text, token.head.pos_, [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4311cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
